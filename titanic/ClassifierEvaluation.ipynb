{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics and plots from Hands-on Machine Learning with Scikit-learn, Keras and Tensorflow\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML, display\n",
    "from tabulate import tabulate\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import (confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "                             precision_recall_curve, roc_curve)\n",
    "from sklearn.ensemble import (AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier,\n",
    "                              ExtraTreesClassifier)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from model import _column_transformer\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "X = df.drop(columns=['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'])\n",
    "y = df['Survived']\n",
    "column_transformer = _column_transformer(X.columns)\n",
    "\n",
    "ada_boost = AdaBoostClassifier()\n",
    "gradient_boosting = GradientBoostingClassifier()\n",
    "random_forest = RandomForestClassifier()\n",
    "extra_tree = ExtraTreesClassifier()\n",
    "k_neighbors = KNeighborsClassifier()\n",
    "svc = SVC(kernel='poly')\n",
    "logistic_regression = LogisticRegression(max_iter=1000)\n",
    "classifiers = [ada_boost, gradient_boosting, random_forest, extra_tree, k_neighbors, svc, logistic_regression]\n",
    "\n",
    "# Calculate predictions and scores\n",
    "preds_and_scores = dict()\n",
    "for clf in classifiers:\n",
    "    pipeline = make_pipeline(column_transformer, clf)\n",
    "    y_pred = cross_val_predict(pipeline, X, y, cv=3)\n",
    "    if hasattr(clf, 'decision_function'):\n",
    "        y_scores = cross_val_predict(pipeline, X, y, cv=3, method='decision_function')\n",
    "    else:\n",
    "        y_scores = cross_val_predict(pipeline, X, y, cv=3, method='predict_proba')\n",
    "        y_scores = y_scores[:, 1]  # Get only positive cases\n",
    "    preds_and_scores[type(clf).__name__] = [y_pred, y_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics\n",
    "headers = ['Precision', 'Recall', 'F1 score', 'ROC AUC score', 'TN', 'FN', 'TP', 'FP']\n",
    "rows = []\n",
    "for clf in classifiers:\n",
    "    y_pred, y_scores = preds_and_scores[type(clf).__name__]\n",
    "    cm = confusion_matrix(y, y_pred).tolist()\n",
    "    rows.append([\n",
    "        type(clf).__name__,\n",
    "        roc_auc_score(y, y_scores),\n",
    "        precision_score(y, y_pred),\n",
    "        recall_score(y, y_pred),\n",
    "        f1_score(y, y_pred),\n",
    "        cm[0][0], cm[0][1], cm[1][1], cm[1][0],])\n",
    "rows.sort(key=lambda row: row[1], reverse=True]['??'=pl;./p[;./09k,.m]])  \n",
    "display(HTML(tabulate(rows, headers=headers, tablefmt='html')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision x recall\n",
    "fig, axs = plt.subplots(len(classifiers), figsize=(10, 20))\n",
    "fig.tight_layout(pad=3.0)\n",
    "plt.xlabel('Thresholds')\n",
    "for i, clf in enumerate(classifiers):\n",
    "    _, y_scores = preds_and_scores[type(clf).__name__]\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y, y_scores)\n",
    "    axs[i].plot(thresholds, precisions[:-1], 'b--', label='Precision')\n",
    "    axs[i].plot(thresholds, recalls[:-1], 'g-', label='Recall')\n",
    "    axs[i].legend()\n",
    "    axs[i].set_title(type(clf).__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SVC` is good at finding true negatives but very at bad true positives - it is just predicting more negatives than the others, as can be seen by on its `Precision x Recall` plot. `GradientBoostingClassifier` gets the most true negatives (deaths) while `AdaBoostClassifier` gets the most true positives (survivals). `GradientBoostingClassifier` has the better precision while `AdaBoostClassifier` has the best recall and their F1 score is basically the same. `GradientBoostingClassifier` has the best ROC AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curves\n",
    "for clf in classifiers:\n",
    "    _, y_scores = preds_and_scores[type(clf).__name__]\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_scores)\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=type(clf).__name__)\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Diagonal\n",
    "plt.legend()\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate (Recall)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
