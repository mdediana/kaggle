{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics and plots from Hands-on Machine Learning with Scikit-learn, Keras and Tensorflow\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import (confusion_matrix, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "                             precision_recall_curve, roc_curve)\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from model import _column_transformer\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "X = df.drop(columns=['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'])\n",
    "y = df['Survived']\n",
    "column_transformer = _column_transformer(X.columns)\n",
    "\n",
    "ada_boost = AdaBoostClassifier()\n",
    "gradient_boosting = GradientBoostingClassifier()\n",
    "random_forest = RandomForestClassifier()\n",
    "k_neighbors = KNeighborsClassifier()\n",
    "svc = SVC(kernel='poly')\n",
    "classifiers = [ada_boost, gradient_boosting, random_forest, k_neighbors, svc]\n",
    "\n",
    "def preds_and_scores(clf):\n",
    "    pipeline = make_pipeline(column_transformer, clf)\n",
    "    y_pred = cross_val_predict(pipeline, X, y, cv=3)\n",
    "    if hasattr(clf, 'decision_function'):\n",
    "        y_scores = cross_val_predict(pipeline, X, y, cv=3, method='decision_function')\n",
    "    else:\n",
    "        y_scores = cross_val_predict(pipeline, X, y, cv=3, method='predict_proba')\n",
    "        y_scores = y_scores[:, 1]  # Get only positive cases\n",
    "    return y_pred, y_scores\n",
    "\n",
    "def metrics(clf):\n",
    "    y_pred, y_scores = preds_and_scores(clf)\n",
    "    return {'Confusion matrix': confusion_matrix(y, y_pred).tolist(),\n",
    "            'Precision': precision_score(y, y_pred),\n",
    "            'Recall': recall_score(y, y_pred),\n",
    "            'F1 score': f1_score(y, y_pred),\n",
    "            'ROC AUC score': roc_auc_score(y, y_scores)}\n",
    "\n",
    "def plot_precision_recall(clf):\n",
    "    _, y_scores = preds_and_scores(clf)\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y, y_scores)\n",
    "    plt.plot(thresholds, precisions[:-1], 'b--', label='Precision')\n",
    "    plt.plot(thresholds, recalls[:-1], 'g-', label='Recall')\n",
    "    plt.legend()\n",
    "    plt.gca().set_xlabel('Thresholds')  # gca: get current axis\n",
    "    \n",
    "def plot_roc_curves():\n",
    "    for clf in classifiers:\n",
    "        _, y_scores = preds_and_scores(clf)\n",
    "        fpr, tpr, thresholds = roc_curve(y, y_scores)\n",
    "        plt.plot(fpr, tpr, linewidth=2, label=type(clf).__name__)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Diagonal\n",
    "    plt.legend()\n",
    "    plt.gca().set_xlabel('False Positive Rate')\n",
    "    plt.gca().set_ylabel('True Positive Rate (Recall)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(ada_boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(gradient_boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(k_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics(svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SVC` is good at finding true negatives but very bad true positives - it is just predicting more negatives than the others. `GradientBoostingClassifier` gets the most true negatives (deaths) while `AdaBoostClassifier` gets the most true positives (survivals). `GradientBoostingClassifier` has the better precision while `AdaBoostClassifier` has the best recall and their F1 score is basically the same. `GradientBoostingClassifier` has the best ROC AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall(ada_boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall(gradient_boosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall(random_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall(k_neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_precision_recall(svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curves()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
